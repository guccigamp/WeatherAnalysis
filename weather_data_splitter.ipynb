{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment variables\n",
    "WEATHER_DATA_DIR = 'Database/Weather Data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function `split_csv_by_empty_row` to split a CSV file into two separate DataFrames based on an empty row that separates the tables in the file.\n",
    "\n",
    "Here's how the code works:\n",
    "\n",
    "1. It opens the CSV file specified by the `file_path` using the `open()` function and assigns it to the file object `f`.\n",
    "\n",
    "2. It reads all the lines from the file using the `readlines()` method of the file object and assigns them to the list variable `lines`.\n",
    "\n",
    "3. The code then searches for the empty row in the `lines` list. It does this by using a list comprehension and the `enumerate()` function to iterate over each line in the `lines` list. If a line is empty (after stripping any leading or trailing whitespace), its index is added to the `empty_row_indices` list.\n",
    "\n",
    "4. Assuming there is only one empty row separating the tables in the CSV file, the code assigns the index of the first empty row to the variable `separator_index`.\n",
    "\n",
    "5. The code then splits the lines into two separate lists based on the `separator_index`. The lines before the empty row are assigned to the list variable `table1_lines`, and the lines after the empty row (including the empty row itself) are assigned to the list variable `table2_lines`.\n",
    "\n",
    "6. The code uses the `pd.read_csv()` function from the pandas library to convert the `table1_lines` and `table2_lines` lists into separate DataFrames. It does this by first joining the lines in each list into a single string using `''.join()`, and then passing the resulting string to `io.StringIO()` to create a file-like object that can be read by `pd.read_csv()`.\n",
    "\n",
    "7. The resulting DataFrames are assigned to the variables `metadata_df` and `readings_df`.\n",
    "\n",
    "8. Finally, the function returns the `metadata_df` and `readings_df` DataFrames as a tuple.\n",
    "\n",
    "This function can be used to split a CSV file into two separate DataFrames based on an empty row, which can be useful for further processing or analysis of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv_by_empty_row(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the empty row\n",
    "    empty_row_indices = [i for i, line in enumerate(lines) if line.strip() == '']\n",
    "\n",
    "    # Assuming there's only one empty row separating the tables\n",
    "    separator_index = empty_row_indices[0]\n",
    "\n",
    "    # Split the lines into two lists based on the separator index\n",
    "    table1_lines = lines[:separator_index]\n",
    "    table2_lines = lines[separator_index + 1:]\n",
    "\n",
    "    # Convert the lists of lines to DataFrames\n",
    "    metadata_df = pd.read_csv(io.StringIO(''.join(table1_lines)))\n",
    "    readings_df = pd.read_csv(io.StringIO(''.join(table2_lines)))\n",
    "\n",
    "    return metadata_df, readings_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the CSV file into two DataFrames and merging them back together\n",
    "\n",
    "1. Initializes an empty list called `all_dfs` which will be used to store datasets.\n",
    "\n",
    "2. Loops through the files in the `WEATHER_DATA_DIR` directory.\n",
    "\n",
    "3. Checks if the file has a `.csv` extension.\n",
    "\n",
    "4. If the file is a `.csv` file, it proceeds to split the CSV file into two DataFrames using the `split_csv_by_empty_row()` function. The resulting DataFrames are assigned to `metadata_df` and `readings_df`.\n",
    "\n",
    "5. Adds new columns ('latitude', 'longitude', 'elevation', 'timezone', 'timezone_abbreviation') to the `readings_df` DataFrame.\n",
    "\n",
    "6. Merges the `metadata_df` and `readings_df` DataFrames based on the 'location_id' column using the `pd.merge()` function. The merged DataFrame is assigned to `merged_df`.\n",
    "\n",
    "7. Drops redundant columns ('latitude_y', 'longitude_y', 'elevation_y', 'timezone_y', 'timezone_abbreviation_y') from the `merged_df` DataFrame using the `drop()` method.\n",
    "\n",
    "8. Saves the merged DataFrame to a new CSV file in the `WEATHER_DATA_DIR` directory, overwriting the original file.\n",
    "\n",
    "This code essentially processes each CSV file in the specified directory, adds new columns to the readings data, merges it with metadata, and saves the merged data back to the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list that will be populated with the datasets\n",
    "all_dfs = []\n",
    "\n",
    "# Loops through the files in the Datasets directory\n",
    "for file in os.listdir(WEATHER_DATA_DIR):\n",
    "\n",
    "    # Executes only the .csv files\n",
    "    if(file.endswith('.csv')):\n",
    "\n",
    "        # Split the CSV into two DataFrames\n",
    "        metadata_df, readings_df = split_csv_by_empty_row(f'{WEATHER_DATA_DIR}/{file}')\n",
    "        \n",
    "        # Create new columns in readings_df\n",
    "        readings_df['latitude'] = ''\n",
    "        readings_df['longitude'] = ''\n",
    "        readings_df['elevation'] = ''\n",
    "        readings_df['timezone'] = ''\n",
    "        readings_df['timezone_abbreviation'] = ''\n",
    "\n",
    "        # Merge metadata_df and readings_df based on location_id of both DataFrames\n",
    "        merged_df = pd.merge(metadata_df, readings_df, on='location_id')\n",
    "\n",
    "        # Drop the reduncant columns\n",
    "        merged_df.drop(columns=['latitude_y', 'longitude_y', 'elevation_y', 'timezone_y', 'timezone_abbreviation_y'], inplace=True)\n",
    "\n",
    "        # Save the merged DataFrame to their respective csv file\n",
    "        merged_df.to_csv(f'{WEATHER_DATA_DIR}/{file}', index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the Redundant fields and Renaming the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through the files in the Datasets directory\n",
    "for file in os.listdir(WEATHER_DATA_DIR):\n",
    "    # Read the csv file\n",
    "    df = pd.read_csv(f'{WEATHER_DATA_DIR}/{file}')\n",
    "\n",
    "    # Rename the columns\n",
    "    df.rename(columns={'latitude_x': 'latitude', 'longitude_x': 'longitude', 'elevation_x': 'elevation', 'timezone_x': 'timezone', 'timezone_abbreviation_x': 'timezone_abbreviation'}, inplace=True)\n",
    "\n",
    "    # Drop the reduncant columns\n",
    "    df.drop(columns=['timezone', 'utc_offset_seconds'], inplace=True)\n",
    "\n",
    "    # Save the DataFrame to their respective csv file\n",
    "    df.to_csv(f'{WEATHER_DATA_DIR}/{file}', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
